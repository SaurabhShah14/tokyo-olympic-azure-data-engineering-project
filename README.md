# tokyo-olympic-azure-data-engineering-project
It is a End-to-End Azure Data Engineering Project
![Picture1](https://github.com/user-attachments/assets/4174616f-9b93-422c-bc65-4f29782bbf67)


I built an end-to-end data engineering solution using Microsoft Azure Cloud services. This project allowed me to explore various Azure components, including Azure Data Factory, Azure Data Lake, Azure Databricks, and Azure Synapse Analytics.

Project Overview
In this project, I imported data from a CSV file hosted on GitHub into Azure Data Lake using Azure Data Factory. This initial step helped me understand the concepts of Storage Accounts and Containers within Azure. ğŸ“Š

Data Transformation
After successfully loading the data into Azure Data Lake, I utilized Azure Databricks for basic data transformation. Here, I learned how to mount the Data Lake container to Databricks, enabling me to access and manipulate the data using Apache Spark. Additionally, I explored the use of Azure Key Vault for managing secrets and app registration for secure access to Azure resources. ğŸ”’

Data Analysis
Once the data was transformed, I saved it back into the Data Lake. The final step involved passing this transformed data to Azure Synapse Analytics for analytical purposes. I performed basic SQL queries to derive insights from the data, enhancing my understanding of how to leverage Azure for data analytics. ğŸ“ˆ

Key Learnings
Throughout this project, I gained practical experience with:
Azure Data Factory: Understanding data ingestion and pipeline creation. ğŸš€
Azure Data Lake: Managing storage and data organization. ğŸ—„ï¸
Azure Databricks: Performing data transformations using Spark. âš¡
Azure Synapse Analytics: Conducting data analysis using SQL. ğŸ§®

This hands-on experience has significantly boosted my confidence in working with Azure Cloud services, and I am eager to continue exploring the vast capabilities of the Azure ecosystem! ğŸŒğŸ’ª
